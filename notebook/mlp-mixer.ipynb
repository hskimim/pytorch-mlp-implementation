{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:00:38.757352Z",
     "start_time": "2022-02-25T17:00:38.752321Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../pytorch-transformers-implementation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:00:38.866928Z",
     "start_time": "2022-02-25T17:00:38.862021Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:39.890747Z",
     "start_time": "2022-02-25T17:03:39.884719Z"
    }
   },
   "outputs": [],
   "source": [
    "from vision_transformer.dataset.iterator import ImageNetIterator\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:40.835521Z",
     "start_time": "2022-02-25T17:03:40.093721Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter = ImageNetIterator(root='../imagenet/',\n",
    "                 height=256,\n",
    "                 width=256,\n",
    "                 is_train=True,\n",
    "                 in_memory=False,\n",
    "                 verbose=False)\n",
    "\n",
    "test_iter = ImageNetIterator(root='../imagenet/',\n",
    "                 height=256,\n",
    "                 width=256,\n",
    "                 is_train=True,\n",
    "                 in_memory=False,\n",
    "                 verbose=False)\n",
    "\n",
    "train_loader = DataLoader(train_iter, batch_size=64*2, shuffle=True, num_workers=10)\n",
    "valid_loader = DataLoader(test_iter, batch_size=64*2, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:40.845624Z",
     "start_time": "2022-02-25T17:03:40.837854Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 height,\n",
    "                 width,\n",
    "                 channel,\n",
    "                 patch,\n",
    "                 C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "        self.patch_size = patch ** 2\n",
    "        img_size = height * width\n",
    "        assert img_size % self.patch_size == 0, 'img is not divisible with patch'\n",
    "\n",
    "        self.seq_length = img_size // self.patch_size\n",
    "        input_dim = self.patch_size * channel\n",
    "        self.patch_emb = nn.Linear(input_dim, C)\n",
    "\n",
    "    def forward(self, img):\n",
    "        N, C, H, W = img.shape\n",
    "\n",
    "        splitted = img.view(N, C, -1).split(self.patch_size, -1)  # [N, C, H*W]\n",
    "        stacked_tensor = torch.stack(splitted, dim=2)  # [N, C, (H*W)/(P**2), P**2]\n",
    "\n",
    "        stacked_tensor = stacked_tensor.permute(0, 2, 1, 3).contiguous()  # [N, (H*W)/(P**2), C, P**2]\n",
    "        stacked_tensor = stacked_tensor.view(N, stacked_tensor.shape[1], -1)  # [N, (H*W)/(P**2), C * P**2]\n",
    "        # S(sequence length) : (H*W)/(P**2)\n",
    "\n",
    "        embeddings = self.patch_emb(stacked_tensor)  # [N, S, C]        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:43.513397Z",
     "start_time": "2022-02-25T17:03:41.387195Z"
    }
   },
   "outputs": [],
   "source": [
    "for (x,y) in train_loader : \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:43.600231Z",
     "start_time": "2022-02-25T17:03:43.517798Z"
    }
   },
   "outputs": [],
   "source": [
    "h, w, c = 256, 256, 3\n",
    "p = 32\n",
    "C=  256\n",
    "\n",
    "pe = PatchEmbedding(h, w, c, p, C)\n",
    "emb = pe(x)\n",
    "S = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:03:43.612972Z",
     "start_time": "2022-02-25T17:03:43.602512Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mixer(nn.Module) : \n",
    "    def __init__(self, input_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.w2 = nn.Linear(hidden_dim, input_dim)\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        normalized_x = self.ln(x)\n",
    "        projected = self.w1(normalized_x)\n",
    "        activated = self.act(projected)\n",
    "        return x + self.w2(activated)\n",
    "    \n",
    "class MixerBlock(nn.Module) : \n",
    "    def __init__(self, channel_mixer, token_mixer) :\n",
    "        super().__init__()\n",
    "        self.cm = channel_mixer\n",
    "        self.tm = token_mixer\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        u = self.cm(x)\n",
    "        ut = u.permute(0,2,1).contiguous()\n",
    "        y = self.tm(ut)\n",
    "        return y.permute(0,2,1).contiguous()\n",
    "    \n",
    "class MM(nn.Module) : \n",
    "    def __init__(self, \n",
    "                 height,\n",
    "                 width,\n",
    "                 channel,\n",
    "                 num_layers,\n",
    "                 patch_size,\n",
    "                 C,\n",
    "                 S,\n",
    "                 D_c,\n",
    "                 D_s,\n",
    "                 output_dim) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pe = PatchEmbedding(height,\n",
    "                            width,\n",
    "                            channel,\n",
    "                            patch_size,\n",
    "                            C)\n",
    "        \n",
    "        channel_mixer = Mixer(C, D_c)\n",
    "        token_mixer = Mixer(S, D_s)\n",
    "        mixer = MixerBlock(channel_mixer, token_mixer)\n",
    "        \n",
    "        self.encoders = nn.ModuleList([deepcopy(mixer) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(C, output_dim)\n",
    "        \n",
    "    def forward(self, x) : \n",
    "        emb = self.pe(x)\n",
    "        for enc in self.encoders : \n",
    "            emb = enc(emb)\n",
    "            \n",
    "        return self.fc(emb.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:04:26.374630Z",
     "start_time": "2022-02-25T17:04:26.239723Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model = nn.DataParallel(MM(h, w, c, 6, p, C, S, 2048, 256, len(train_iter.label_dict)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:04:26.620502Z",
     "start_time": "2022-02-25T17:04:26.615306Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:04:26.855739Z",
     "start_time": "2022-02-25T17:04:26.845609Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:04:27.268289Z",
     "start_time": "2022-02-25T17:04:27.247143Z"
    }
   },
   "outputs": [],
   "source": [
    "def train() : \n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for x,y in tqdm(train_loader, desc='train') : \n",
    "        pred = model(x.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(pred, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (torch.argmax(pred, dim=1) == y.to(device)).sum()\n",
    "        acc = correct.item() / y.shape[0]\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    agg_acc = sum(accuracies) / len(accuracies)\n",
    "    agg_loss = sum(losses) / len(losses)\n",
    "    return agg_acc, agg_loss\n",
    "\n",
    "def evalulate() : \n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for x,y in tqdm(valid_loader, desc='valid') : \n",
    "        pred = model(x.to(device))\n",
    "\n",
    "        loss = criterion(pred, y.to(device))\n",
    "        correct = (torch.argmax(pred, dim=1) == y.to(device)).sum()\n",
    "        acc = correct.item() / y.shape[0]\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    agg_acc = sum(accuracies) / len(accuracies)\n",
    "    agg_loss = sum(losses) / len(losses)\n",
    "    return agg_acc, agg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-25T17:13:32.941Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3693b9652b4e0685b017117b625a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d30fd7247124310ba52e5eed050d7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 1th Epoch ===\n",
      "    \n",
      "        Train Loss : 3.89 | Train Acc : 0.143\n",
      "        Valid Loss : 3.412 | Valid Acc : 0.211\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0474dad992429187269612c6eff8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74064902ab864006b61d16f414f533fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 2th Epoch ===\n",
      "    \n",
      "        Train Loss : 3.244 | Train Acc : 0.239\n",
      "        Valid Loss : 2.925 | Valid Acc : 0.292\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89db16783fa4375a27d6aee83eef8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b30702e87b46e89529839954d977be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 3th Epoch ===\n",
      "    \n",
      "        Train Loss : 2.966 | Train Acc : 0.289\n",
      "        Valid Loss : 2.652 | Valid Acc : 0.346\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0ce42a16f9492497ead4e05fe783b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6044c8105d254979a52c63db4868e9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                === 4th Epoch ===\n",
      "    \n",
      "        Train Loss : 2.725 | Train Acc : 0.333\n",
      "        Valid Loss : 2.35 | Valid Acc : 0.405\n",
      "        \n",
      "        ============================================\n",
      "        ============================================\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac719357fc624155b7c84d9b1fd2bb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9423563da52f48648f2f1b2c5650b42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoches = 20\n",
    "\n",
    "for proc in range(epoches) : \n",
    "    t_acc, t_loss = train()\n",
    "    v_acc, v_loss = evalulate()\n",
    "    print(f\"\"\"\n",
    "                === {proc+1}th Epoch ===\n",
    "    \n",
    "        Train Loss : {round(t_loss, 3)} | Train Acc : {round(t_acc, 3)}\n",
    "        Valid Loss : {round(v_loss, 3)} | Valid Acc : {round(v_acc, 3)}\n",
    "        \n",
    "        ============================================\n",
    "        ============================================\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
